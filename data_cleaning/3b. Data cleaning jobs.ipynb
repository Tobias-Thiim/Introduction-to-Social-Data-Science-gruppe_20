{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Relevante pakker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "from pathlib import Path # To make relative paths\n",
    "pd.options.display.max_columns = None\n",
    "# pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define relevant paths\n",
    "For the following code to rund you should have a project folder with the two subfolders \"Code\" and \"Data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('C:/Users/nld/Introduction to Data Science/Exam Project/Data')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_path = Path.cwd() # Path to current directory\n",
    "project_path = my_path.parents[0] # Path to project directory\n",
    "data_path = project_path / 'Data' # Path to data folder\n",
    "data_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indlæser data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17980"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_df = pd.read_csv(data_path/'final_job_postings.csv', encoding = 'utf-8')\n",
    "len(job_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dubletter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dubletter:8\n",
      "17980\n",
      "17972\n"
     ]
    }
   ],
   "source": [
    "# Tjekker for dubletter i data\n",
    "print(\"Dubletter:\" + str(len(job_df[job_df.duplicated()])))\n",
    "job_df[job_df.duplicated()]\n",
    "# Find all duplicate rows\n",
    "duplicates = job_df[job_df.duplicated(keep=False)]\n",
    "print(len(job_df))\n",
    "\n",
    "# Fjerner dubletter\n",
    "job_df = job_df.drop_duplicates()\n",
    "print(len(job_df))\n",
    "duplicates_in_presentation.to_csv(data_path / 'job_dubletter.csv', sep=';', index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Undersøger nu om der er dubletter på andre variable\n",
    "job_df\n",
    "\n",
    "# Find all rows where the 'Presentation' column has duplicate values\n",
    "duplicates_in_presentation = job_df[job_df[['Title', 'JobHeadline', 'Presentation', 'WorkPlaceAddress']].duplicated(keep=False)]\n",
    "\n",
    "# Display the duplicate rows\n",
    "duplicates_in_presentation = duplicates_in_presentation.sort_values(['Title', 'JobHeadline', 'Presentation', 'WorkPlaceAddress'])\n",
    "\n",
    "# Vi finder at det er reelt nok, at disse jobopslag ligger flere gange, da teksten er forskellig, når \n",
    "# vi går ind på links\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Renser data\n",
    "1. Fjerner jobopslag med arbejdssted uden for DK\n",
    "2. Fjerner jobopslag med manglende gps-koordinater"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17972\n",
      "17760\n"
     ]
    }
   ],
   "source": [
    "# Fjerner jobopslag med arbejdsstuden for DK\n",
    "print(len(job_df))\n",
    "job_df_cleaned = job_df[job_df['Country']==\"Danmark\"]\n",
    "print(len(job_df_cleaned))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_df_cleaned.groupby('HasLocationValues').size()\n",
    "test = job_df_cleaned[job_df_cleaned['HasLocationValues']==False]\n",
    "test.to_csv(data_path / 'job_missing_location.csv', sep=';', index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17760\n",
      "17646\n"
     ]
    }
   ],
   "source": [
    "print(len(job_df_cleaned))\n",
    "job_df_cleaned = job_df[job_df['HasLocationValues']==True]\n",
    "print(len(job_df_cleaned))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eksport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eksporterer data\n",
    "job_df_cleaned.to_csv(data_path / 'jobs_cleaned.csv', sep=';', index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
